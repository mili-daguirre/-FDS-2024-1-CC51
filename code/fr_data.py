# -*- coding: utf-8 -*-
"""FR_data

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/12GIk8AhH6EY-OFF2EsO-Xog28Q4EFOo-

# Creación de conocimiento aplicando la metodología CRISP-DM
"""

# Tratamiento de datos
# ==============================================================================
import numpy as np
import pandas as pd

# Gráficos
# ==============================================================================
import matplotlib.pyplot as plt
from matplotlib import style
import matplotlib.ticker as ticker
import seaborn as sns

# Preprocesado y modelado
# ==============================================================================
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import StratifiedKFold
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import  roc_curve, auc, silhouette_score, recall_score, precision_score, confusion_matrix, accuracy_score
from sklearn import metrics
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.impute import SimpleImputer

"""leer el archivo FRvideos_cc50_202101.csv y cargarlo al dataFrame DATA

"""

path='FRvideos_cc50_202101.csv'
data = pd.read_csv(path, sep=',')
data.head()



"""# COMPRESION DE LOS DATOS"""

# Descripción de los datos
data.info()
data.describe()

# Visualización inicial
sns.histplot(data['views'], bins=30, kde=True)
plt.title('Distribución de Vistas')
plt.show()

sns.histplot(data['likes'], bins=30, kde=True)
plt.title('Distribución de Me Gusta')
plt.show()

sns.histplot(data['dislikes'], bins=30, kde=True)
plt.title('Distribución de No Me Gusta')
plt.show()

sns.histplot(data['comment_count'], bins=30, kde=True)
plt.title('Distribución de Comentarios')
plt.show()

"""# PREPARACION DE LOS DATOS"""

# Verificación de valores nulos
print(data.isnull().sum())

# Imputar valores nulos con la mediana de la columna
imputer = SimpleImputer(strategy='median')
data[['views', 'likes', 'dislikes', 'comment_count']] = imputer.fit_transform(data[['views', 'likes', 'dislikes', 'comment_count']])

# Verificar que no hay valores nulos
print(data.isnull().sum())

# Guardar el conjunto de datos final limpio
data.to_csv('FRvideos_cc50_202101_clean.csv', index=False)

# Aplicar transformación logarítmica
data['log_views'] = np.log(data['views'] + 1)
data['log_likes'] = np.log(data['likes'] + 1)
data['log_dislikes'] = np.log(data['dislikes'] + 1)
data['log_comment_count'] = np.log(data['comment_count'] + 1)

# Verificar las nuevas distribuciones
sns.histplot(data['log_views'], bins=30, kde=True)
plt.title('Distribución Logarítmica de Vistas')
plt.show()

sns.histplot(data['log_likes'], bins=30, kde=True)
plt.title('Distribución Logarítmica de Me Gusta')
plt.show()

sns.histplot(data['log_dislikes'], bins=30, kde=True)
plt.title('Distribución Logarítmica de No Me Gusta')
plt.show()

sns.histplot(data['log_comment_count'], bins=30, kde=True)
plt.title('Distribución Logarítmica de Comentarios')
plt.show()

#creacion de nuevas caracteristicas
# Crear nueva característica de popularidad
data['popularity_ratio'] = data['likes'] / (data['likes'] + data['dislikes'])

# Handle potential NaN values (replace with 0 in this case)
data['popularity_ratio'].fillna(0, inplace=True)

"""# MODELIZACION Y EVALUACION

"""

# Selección de características y variable objetivo
# Selección de características y variable objetivo
X = data[['log_views', 'log_comment_count', 'popularity_ratio']]
y = data['log_likes']

# División del conjunto de datos
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Verificación final de valores nulos en los conjuntos de entrenamiento y prueba
print(X_train.isnull().sum())
print(X_test.isnull().sum())

# Construcción del modelo
model = LinearRegression()
model.fit(X_train, y_train)

# Evaluación del modelo
y_pred = model.predict(X_test)
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print(f'Mean Squared Error: {mse}')
print(f'R^2 Score: {r2}')

"""# Requerimientos"""

# Requerimiento 1: Categorías de videos de mayor tendencia
category_trend = data['category_id'].value_counts().head(10)
sns.barplot(x=category_trend.index, y=category_trend.values)
plt.title('Categorías con Mayor Número de Videos en Tendencia')
plt.xlabel('Categoría')
plt.ylabel('Número de Videos')
plt.show()

# Requerimiento 2: Categorías de videos más y menos gustados
category_likes = data.groupby('category_id')['likes'].mean().sort_values(ascending=False)
sns.barplot(x=category_likes.index, y=category_likes.values)
plt.title('Categorías con Más Me Gusta (Promedio)')
plt.xlabel('Categoría')
plt.ylabel('Promedio de Me Gusta')
plt.show()

# Requerimiento 3: Mejor proporción "Me gusta" / "No me gusta"
category_ratio = data.groupby('category_id')['popularity_ratio'].mean().sort_values(ascending=False)
sns.barplot(x=category_ratio.index, y=category_ratio.values)
plt.title('Categorías con Mejor Proporción Me Gusta / No Me Gusta')
plt.xlabel('Categoría')
plt.ylabel('Proporción Me Gusta / No Me Gusta')
plt.show()

# Requerimiento 4: Mejor proporción "Vistas" / "Comentarios"
data['views_comments_ratio'] = data['views'] / (data['comment_count'] + 1)
category_views_comments_ratio = data.groupby('category_id')['views_comments_ratio'].mean().sort_values(ascending=False)
sns.barplot(x=category_views_comments_ratio.index, y=category_views_comments_ratio.values)
plt.title('Categorías con Mejor Proporción Vistas / Comentarios')
plt.xlabel('Categoría')
plt.ylabel('Proporción Vistas / Comentarios')
plt.show()

# Requerimiento 5: Cambio en volumen de videos en tendencia a lo largo del tiempo
data['trending_date'] = pd.to_datetime(data['trending_date'], format='%y.%d.%m')
trend_over_time = data['trending_date'].value_counts().sort_index()
trend_over_time.plot()
plt.title('Cambio en Volumen de Videos en Tendencia a lo Largo del Tiempo')
plt.xlabel('Fecha')
plt.ylabel('Número de Videos en Tendencia')
plt.show()

# Requerimiento 6: Canales de YouTube con mayor y menor frecuencia en tendencia
channels_trend = data['channel_title'].value_counts()
top_channels = channels_trend.head(10)
bottom_channels = channels_trend.tail(10)
sns.barplot(x=top_channels.values, y=top_channels.index)
plt.title('Canales con Mayor Frecuencia en Tendencia')
plt.xlabel('Número de Videos en Tendencia')
plt.ylabel('Canal')
plt.show()

sns.barplot(x=bottom_channels.values, y=bottom_channels.index)
plt.title('Canales con Menor Frecuencia en Tendencia')
plt.xlabel('Número de Videos en Tendencia')
plt.ylabel('Canal')
plt.show()

# Requerimiento 7: Estados con mayor número de 'Vistas', 'Me gusta' y 'No me gusta'
states_views = data.groupby('state')['views'].sum().sort_values(ascending=False)
states_likes = data.groupby('state')['likes'].sum().sort_values(ascending=False)
states_dislikes = data.groupby('state')['dislikes'].sum().sort_values(ascending=False)

# Visualización
fig, axs = plt.subplots(3, 1, figsize=(10, 15))

sns.barplot(x=states_views.values, y=states_views.index, ax=axs[0])
axs[0].set_title('Estados con Mayor Número de Vistas')
axs[0].set_xlabel('Número de Vistas')

sns.barplot(x=states_likes.values, y=states_likes.index, ax=axs[1])
axs[1].set_title('Estados con Mayor Número de Me Gusta')
axs[1].set_xlabel('Número de Me Gusta')

sns.barplot(x=states_dislikes.values, y=states_dislikes.index, ax=axs[2])
axs[2].set_title('Estados con Mayor Número de No Me Gusta')
axs[2].set_xlabel('Número de No Me Gusta')

plt.tight_layout()
plt.show()

# Requerimiento 8: Predicción de 'Me gusta'
X = data[['log_views', 'log_comment_count', 'popularity_ratio']]
y = data['log_likes']

# Verificación final y eliminación de valores nulos en X e y
X = X.dropna()
y = y[X.index]

# División del conjunto de datos
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Construcción del modelo
model = LinearRegression()
model.fit(X_train, y_train)

# Evaluación del modelo
y_pred = model.predict(X_test)
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print(f'Mean Squared Error: {mse}')
print(f'R^2 Score: {r2}')

# Requerimiento 9: Videos en tendencia y comentarios positivos
trend_comments = data[['title', 'comment_count']].sort_values(by='comment_count', ascending=False).head(10)
print(trend_comments)
